{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "cabcfdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1c8656a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Admission_Predict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "58d5ccc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e4b5b4fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 9)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e5d1cf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "546dc143",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,1:-1]\n",
    "Y=df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "cb346956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "1          324          107                  4  4.0   4.5  8.87         1\n",
       "2          316          104                  3  3.0   3.5  8.00         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "4          314          103                  2  2.0   3.0  8.21         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "395        324          110                  3  3.5   3.5  9.04         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "397        330          116                  4  5.0   4.5  9.45         1\n",
       "398        312          103                  3  3.5   4.0  8.78         0\n",
       "399        333          117                  4  5.0   4.0  9.66         1\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9b497901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.92\n",
       "1      0.76\n",
       "2      0.72\n",
       "3      0.80\n",
       "4      0.65\n",
       "       ... \n",
       "395    0.82\n",
       "396    0.84\n",
       "397    0.91\n",
       "398    0.67\n",
       "399    0.95\n",
       "Name: Chance of Admit , Length: 400, dtype: float64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ff3e6920",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c84790ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled=MinMaxScaler().fit_transform(X_train)\n",
    "X_test_scaled=MinMaxScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "1baecb09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38      , 0.57142857, 0.5       , ..., 0.5       , 0.42307692,\n",
       "        0.        ],\n",
       "       [0.56      , 0.28571429, 0.25      , ..., 0.625     , 0.55769231,\n",
       "        1.        ],\n",
       "       [0.62      , 0.60714286, 0.5       , ..., 0.75      , 0.44871795,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.48      , 0.53571429, 0.25      , ..., 0.75      , 0.47115385,\n",
       "        0.        ],\n",
       "       [0.68      , 0.64285714, 0.75      , ..., 0.75      , 0.75320513,\n",
       "        1.        ],\n",
       "       [0.8       , 0.78571429, 0.75      , ..., 0.5       , 0.75961538,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "1c24283a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7826087 , 0.74074074, 1.        , 1.        , 0.66666667,\n",
       "        0.76470588, 1.        ],\n",
       "       [0.41304348, 0.51851852, 0.25      , 0.28571429, 0.        ,\n",
       "        0.44705882, 1.        ],\n",
       "       [0.63043478, 0.51851852, 0.5       , 0.57142857, 0.5       ,\n",
       "        0.46666667, 1.        ],\n",
       "       [0.39130435, 0.59259259, 0.5       , 0.42857143, 0.33333333,\n",
       "        0.52156863, 0.        ],\n",
       "       [0.30434783, 0.48148148, 0.5       , 0.42857143, 0.33333333,\n",
       "        0.34509804, 0.        ],\n",
       "       [0.30434783, 0.62962963, 0.75      , 0.57142857, 0.33333333,\n",
       "        0.48627451, 0.        ],\n",
       "       [0.60869565, 0.62962963, 0.5       , 0.42857143, 0.5       ,\n",
       "        0.25098039, 0.        ],\n",
       "       [0.65217391, 0.77777778, 1.        , 1.        , 0.83333333,\n",
       "        0.6745098 , 1.        ],\n",
       "       [0.19565217, 0.18518519, 0.        , 0.14285714, 0.16666667,\n",
       "        0.11372549, 0.        ],\n",
       "       [0.10869565, 0.14814815, 0.5       , 1.        , 0.5       ,\n",
       "        0.11764706, 0.        ],\n",
       "       [0.63043478, 0.74074074, 0.75      , 0.71428571, 0.83333333,\n",
       "        0.73333333, 1.        ],\n",
       "       [0.58695652, 0.59259259, 0.75      , 0.71428571, 0.66666667,\n",
       "        0.69411765, 1.        ],\n",
       "       [0.60869565, 0.7037037 , 0.75      , 0.85714286, 0.83333333,\n",
       "        0.74509804, 1.        ],\n",
       "       [1.        , 0.77777778, 1.        , 0.71428571, 0.66666667,\n",
       "        0.87843137, 1.        ],\n",
       "       [0.47826087, 0.48148148, 0.25      , 0.28571429, 0.66666667,\n",
       "        0.37647059, 0.        ],\n",
       "       [0.2173913 , 0.14814815, 0.25      , 0.        , 0.        ,\n",
       "        0.10980392, 0.        ],\n",
       "       [0.65217391, 0.66666667, 1.        , 0.85714286, 0.66666667,\n",
       "        0.70588235, 1.        ],\n",
       "       [0.52173913, 0.59259259, 0.5       , 0.42857143, 0.33333333,\n",
       "        0.44705882, 0.        ],\n",
       "       [0.47826087, 0.44444444, 0.25      , 0.28571429, 0.16666667,\n",
       "        0.32941176, 1.        ],\n",
       "       [0.63043478, 0.55555556, 0.5       , 0.57142857, 0.33333333,\n",
       "        0.48627451, 0.        ],\n",
       "       [0.41304348, 0.51851852, 0.5       , 0.71428571, 0.83333333,\n",
       "        0.52156863, 0.        ],\n",
       "       [0.91304348, 0.92592593, 1.        , 0.85714286, 0.66666667,\n",
       "        0.71764706, 1.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.60869565, 0.62962963, 0.75      , 0.71428571, 1.        ,\n",
       "        0.69411765, 1.        ],\n",
       "       [0.43478261, 0.44444444, 0.5       , 0.57142857, 0.16666667,\n",
       "        0.36862745, 0.        ],\n",
       "       [0.58695652, 0.62962963, 0.5       , 0.57142857, 1.        ,\n",
       "        0.58431373, 1.        ],\n",
       "       [0.7173913 , 0.66666667, 0.75      , 0.71428571, 0.83333333,\n",
       "        0.64313725, 1.        ],\n",
       "       [0.10869565, 0.25925926, 0.        , 0.        , 0.        ,\n",
       "        0.20784314, 0.        ],\n",
       "       [0.5       , 0.37037037, 0.25      , 0.28571429, 0.        ,\n",
       "        0.30980392, 0.        ],\n",
       "       [0.02173913, 0.2962963 , 0.25      , 0.28571429, 0.        ,\n",
       "        0.19607843, 0.        ],\n",
       "       [0.86956522, 0.88888889, 1.        , 0.71428571, 0.83333333,\n",
       "        0.67058824, 1.        ],\n",
       "       [0.43478261, 0.48148148, 0.25      , 0.71428571, 0.5       ,\n",
       "        0.34901961, 0.        ],\n",
       "       [0.58695652, 0.66666667, 0.5       , 0.28571429, 0.33333333,\n",
       "        0.60392157, 1.        ],\n",
       "       [0.63043478, 0.62962963, 1.        , 0.71428571, 1.        ,\n",
       "        0.63529412, 1.        ],\n",
       "       [0.41304348, 0.2962963 , 0.5       , 0.28571429, 0.33333333,\n",
       "        0.26666667, 0.        ],\n",
       "       [0.39130435, 0.40740741, 0.5       , 0.57142857, 0.66666667,\n",
       "        0.28627451, 0.        ],\n",
       "       [0.82608696, 0.92592593, 1.        , 1.        , 1.        ,\n",
       "        0.82745098, 1.        ],\n",
       "       [0.30434783, 0.48148148, 0.5       , 0.57142857, 0.16666667,\n",
       "        0.33333333, 1.        ],\n",
       "       [0.76086957, 0.77777778, 0.25      , 0.14285714, 0.66666667,\n",
       "        0.47058824, 1.        ],\n",
       "       [0.34782609, 0.51851852, 0.5       , 0.57142857, 0.5       ,\n",
       "        0.51372549, 0.        ],\n",
       "       [0.76086957, 0.77777778, 1.        , 0.85714286, 1.        ,\n",
       "        0.71764706, 1.        ],\n",
       "       [0.5       , 0.25925926, 0.25      , 0.42857143, 0.16666667,\n",
       "        0.4745098 , 0.        ],\n",
       "       [0.43478261, 0.51851852, 0.5       , 0.42857143, 0.5       ,\n",
       "        0.31764706, 1.        ],\n",
       "       [0.32608696, 0.40740741, 0.25      , 0.14285714, 0.16666667,\n",
       "        0.35294118, 0.        ],\n",
       "       [0.69565217, 0.33333333, 0.75      , 1.        , 1.        ,\n",
       "        0.54901961, 1.        ],\n",
       "       [0.10869565, 0.48148148, 0.25      , 0.71428571, 0.66666667,\n",
       "        0.40784314, 0.        ],\n",
       "       [0.15217391, 0.40740741, 0.25      , 0.57142857, 0.5       ,\n",
       "        0.20784314, 1.        ],\n",
       "       [0.04347826, 0.2962963 , 0.        , 0.28571429, 0.33333333,\n",
       "        0.1254902 , 0.        ],\n",
       "       [0.43478261, 0.33333333, 0.25      , 0.14285714, 0.16666667,\n",
       "        0.34509804, 0.        ],\n",
       "       [0.65217391, 0.62962963, 0.5       , 0.57142857, 0.66666667,\n",
       "        0.59215686, 1.        ],\n",
       "       [0.60869565, 0.59259259, 1.        , 0.85714286, 0.5       ,\n",
       "        0.56470588, 0.        ],\n",
       "       [0.39130435, 0.44444444, 0.25      , 0.28571429, 0.33333333,\n",
       "        0.29803922, 0.        ],\n",
       "       [0.60869565, 0.62962963, 0.5       , 0.57142857, 0.33333333,\n",
       "        0.62745098, 1.        ],\n",
       "       [0.39130435, 0.51851852, 0.25      , 0.28571429, 0.5       ,\n",
       "        0.35686275, 0.        ],\n",
       "       [0.36956522, 0.33333333, 0.5       , 0.85714286, 0.66666667,\n",
       "        0.50196078, 1.        ],\n",
       "       [0.91304348, 0.96296296, 1.        , 0.71428571, 0.5       ,\n",
       "        0.95686275, 1.        ],\n",
       "       [0.2826087 , 0.59259259, 0.5       , 0.71428571, 0.33333333,\n",
       "        0.25098039, 1.        ],\n",
       "       [0.60869565, 0.44444444, 0.25      , 0.42857143, 0.33333333,\n",
       "        0.42745098, 1.        ],\n",
       "       [0.60869565, 0.77777778, 1.        , 0.85714286, 0.66666667,\n",
       "        0.61960784, 1.        ],\n",
       "       [0.56521739, 0.62962963, 1.        , 1.        , 0.83333333,\n",
       "        0.72941176, 1.        ],\n",
       "       [0.7173913 , 0.37037037, 0.5       , 0.71428571, 0.66666667,\n",
       "        0.36862745, 1.        ],\n",
       "       [0.39130435, 0.51851852, 0.5       , 0.42857143, 0.        ,\n",
       "        0.21176471, 1.        ],\n",
       "       [0.36956522, 0.40740741, 0.25      , 0.14285714, 0.        ,\n",
       "        0.36862745, 0.        ],\n",
       "       [0.39130435, 0.62962963, 0.25      , 0.57142857, 0.33333333,\n",
       "        0.45882353, 0.        ],\n",
       "       [0.65217391, 0.62962963, 0.5       , 0.57142857, 0.5       ,\n",
       "        0.65882353, 1.        ],\n",
       "       [0.56521739, 0.2962963 , 0.25      , 0.28571429, 0.33333333,\n",
       "        0.49411765, 0.        ],\n",
       "       [0.86956522, 0.96296296, 1.        , 0.85714286, 0.83333333,\n",
       "        0.83137255, 1.        ],\n",
       "       [0.73913043, 0.62962963, 0.75      , 1.        , 0.66666667,\n",
       "        0.69803922, 1.        ],\n",
       "       [0.95652174, 0.88888889, 0.75      , 0.57142857, 0.83333333,\n",
       "        0.82352941, 1.        ],\n",
       "       [0.86956522, 0.77777778, 0.75      , 0.71428571, 0.66666667,\n",
       "        0.81176471, 1.        ],\n",
       "       [0.58695652, 0.66666667, 1.        , 1.        , 1.        ,\n",
       "        0.81960784, 1.        ],\n",
       "       [0.67391304, 0.62962963, 0.25      , 0.42857143, 0.16666667,\n",
       "        0.54901961, 1.        ],\n",
       "       [0.54347826, 0.48148148, 0.5       , 0.57142857, 0.16666667,\n",
       "        0.38039216, 1.        ],\n",
       "       [0.86956522, 0.85185185, 0.75      , 0.71428571, 0.33333333,\n",
       "        0.25098039, 1.        ],\n",
       "       [0.73913043, 0.62962963, 0.75      , 0.71428571, 0.16666667,\n",
       "        0.65098039, 1.        ],\n",
       "       [0.2826087 , 0.33333333, 0.5       , 0.42857143, 0.33333333,\n",
       "        0.35686275, 0.        ],\n",
       "       [1.        , 1.        , 1.        , 0.85714286, 0.83333333,\n",
       "        1.        , 1.        ],\n",
       "       [0.23913043, 0.33333333, 0.25      , 0.14285714, 0.16666667,\n",
       "        0.32156863, 0.        ],\n",
       "       [0.36956522, 0.44444444, 0.5       , 0.57142857, 0.33333333,\n",
       "        0.42745098, 1.        ],\n",
       "       [0.65217391, 0.7037037 , 0.75      , 0.71428571, 0.5       ,\n",
       "        0.55294118, 1.        ]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e6c62f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(10,activation=\"relu\",input_dim=X_train_scaled.shape[1]))\n",
    "model.add(Dense(10,activation=\"relu\"))\n",
    "model.add(Dense(5,activation=\"relu\"))\n",
    "model.add(Dense(1,activation=\"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "279d2c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_57 (Dense)            (None, 10)                80        \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 5)                 55        \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 251 (1004.00 Byte)\n",
      "Trainable params: 251 (1004.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a774b4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\",optimizer=\"Adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f040bdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 15ms/step - loss: 0.2817 - val_loss: 0.2408\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2065 - val_loss: 0.1672\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1395 - val_loss: 0.1051\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0857 - val_loss: 0.0575\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0463 - val_loss: 0.0265\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0232 - val_loss: 0.0117\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0079\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0116 - val_loss: 0.0083\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0082\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.0076\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0104 - val_loss: 0.0073\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0099 - val_loss: 0.0072\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0096 - val_loss: 0.0073\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0093 - val_loss: 0.0074\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0090 - val_loss: 0.0074\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0089 - val_loss: 0.0075\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0075\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0073\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0073\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0073\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.0073\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0072\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0072\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0071\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0070\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0070\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0070\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0069\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0067 - val_loss: 0.0068\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0067\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0067\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0066\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0065\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0063 - val_loss: 0.0064\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0064\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0061 - val_loss: 0.0063\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0062\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0061\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0061\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0060\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0057\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0056\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0049\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0049\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train_scaled,Y_train,epochs=100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "e42f24db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5af504ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred=model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0ed3b526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6114814004250391"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "12f6e5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'val_loss'])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "70d30c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11846b7e110>]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
